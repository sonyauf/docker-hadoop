{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553aa679-1528-4a35-bb68-b604f961f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark session & context\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc8772-4674-44fc-b6a7-f8841f573604",
   "metadata": {},
   "source": [
    "# Explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ee08d8-79ac-4837-8d85-518041a3c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training data from HDFS\n",
    "train = spark.read.csv('hdfs://namenode:9000//user/root/data/twitter_training.csv', header=False, inferSchema=True)\n",
    "train = train.toDF('id', 'entity', 'sentiment', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871d478e-785e-4be1-a27e-87ae076b2bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+---------+--------------------+\n",
      "|  id|     entity|sentiment|                text|\n",
      "+----+-----------+---------+--------------------+\n",
      "|2401|Borderlands| Positive|im getting on bor...|\n",
      "|2401|Borderlands| Positive|I am coming to th...|\n",
      "|2401|Borderlands| Positive|im getting on bor...|\n",
      "|2401|Borderlands| Positive|im coming on bord...|\n",
      "|2401|Borderlands| Positive|im getting on bor...|\n",
      "+----+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4fccc4f-b8e8-4b4a-befa-58c334b3dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- entity: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9713634-a6ff-4863-999f-7417b403d807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+----+\n",
      "| id|entity|sentiment|text|\n",
      "+---+------+---------+----+\n",
      "|  0|     0|        0| 686|\n",
      "+---+------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Check nulls in each column\n",
    "null_counts = train.select([sum(col(c).isNull().cast('int')).alias(c) for c in train.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3fbc34e-e074-476c-a64c-2292790db761",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.na.drop(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa2a00c-eb04-4345-83ee-d6989371ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|              entity|count|\n",
      "+--------------------+-----+\n",
      "|       Cyberpunk2077| 2262|\n",
      "|         Borderlands| 2280|\n",
      "|       Xbox(Xseries)| 2283|\n",
      "|   PlayStation5(PS5)| 2291|\n",
      "|                FIFA| 2324|\n",
      "|           Overwatch| 2316|\n",
      "|             Verizon| 2365|\n",
      "|        WorldOfCraft| 2357|\n",
      "|      AssassinsCreed| 2234|\n",
      "|PlayerUnknownsBat...| 2234|\n",
      "|               CS-GO| 2284|\n",
      "|         Battlefield| 2316|\n",
      "| GrandTheftAuto(GTA)| 2293|\n",
      "|           HomeDepot| 2292|\n",
      "|               NBA2K| 2343|\n",
      "|              Google| 2274|\n",
      "|               Dota2| 2359|\n",
      "|RedDeadRedemption...| 2249|\n",
      "|CallOfDutyBlackop...| 2343|\n",
      "|     LeagueOfLegends| 2377|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy('entity').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bc019b-87b1-4d5b-a064-c8224ad3843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| sentiment|count|\n",
      "+----------+-----+\n",
      "|Irrelevant|12875|\n",
      "|  Positive|20655|\n",
      "|   Neutral|18108|\n",
      "|  Negative|22358|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42cc92-8ce1-45ac-8d00-3663de523946",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93815df4-e9e6-40fd-97d9-3efaa01415bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0c19125-c663-47b4-973d-79bf4a7e23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure an ML pipeline\n",
    "indexer = StringIndexer(inputCol='sentiment', outputCol=\"label\")\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"meanWords\")\n",
    "hashingTF = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\",\n",
    "                        maxIter=10, regParam=0.01)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, tokenizer, swr, hashingTF, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf4bda4-a26f-424e-b455-87c48d96cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "069ce213-dd03-4110-a2d6-4d5f0550a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary = model.stages[-1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d93ca4d-77cd-4390-88cb-ee770ca3dec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "1.3665632586088805\n",
      "0.6021721834184313\n",
      "0.41003009531871454\n",
      "0.2914972083155612\n",
      "0.24115410758471267\n",
      "0.239130120070332\n",
      "0.23577946649623435\n",
      "0.2156194228609918\n",
      "0.21480625311407978\n",
      "0.213760456761295\n",
      "0.2084295087072241\n"
     ]
    }
   ],
   "source": [
    "# Obtain the objective per iteration\n",
    "objectiveHistory = trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1779b94b-038c-463e-b568-42379e545740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9536326287907454\n",
      "FPR: 0.018070421400974597\n",
      "TPR: 0.9536326287907455\n",
      "F-measure: 0.9538545495344515\n",
      "Precision: 0.9555558822310862\n",
      "Recall: 0.9536326287907455\n"
     ]
    }
   ],
   "source": [
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce4e182-82d5-4047-91dd-703eb35c16e9",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "271d90dc-d50e-44e7-8302-33737d98c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----------+--------------------+\n",
      "|  id|   entity| sentiment|                text|\n",
      "+----+---------+----------+--------------------+\n",
      "|3364| Facebook|Irrelevant|I mentioned on Fa...|\n",
      "| 352|   Amazon|   Neutral|BBC News - Amazon...|\n",
      "|8312|Microsoft|  Negative|@Microsoft Why do...|\n",
      "|4371|    CS-GO|  Negative|CSGO matchmaking ...|\n",
      "|4433|   Google|   Neutral|Now the President...|\n",
      "+----+---------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read test data from HDFS\n",
    "test = spark.read.csv('hdfs://namenode:9000//user/root/data/twitter_validation.csv', header=False, inferSchema=True)\n",
    "test = test.toDF('id', 'entity', 'sentiment', 'text')\n",
    "\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62325294-54d3-4b6b-aa2d-fcbf45b17af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+----+\n",
      "| id|entity|sentiment|text|\n",
      "+---+------+---------+----+\n",
      "|  0|   467|      495| 510|\n",
      "+---+------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nulls in each column\n",
    "null_counts = test.select([sum(col(c).isNull().cast('int')).alias(c) for c in test.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35cda4e2-5512-4f4c-a290-0e84dae8dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ff92154-72d9-47fc-bd96-54c287f6abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| sentiment|count|\n",
      "+----------+-----+\n",
      "|Irrelevant|  172|\n",
      "|   Neutral|  285|\n",
      "|  Positive|  277|\n",
      "|  Negative|  266|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy('sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fc7b6d5-30ad-4224-8a01-60e8b4f1f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ceea6ce-69f2-4072-80ca-ae2c0b7abfd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       3.0|  3.0|\n",
      "|       2.0|  2.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       2.0|  2.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       1.0|  1.0|\n",
      "|       0.0|  0.0|\n",
      "+----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_prediction = prediction.select(\"prediction\", \"label\")\n",
    "final_prediction.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5534f041-670c-4e85-9bf7-43f85a14a0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.906319890000543"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a96a667-d8e7-4e71-93b1-26945f335062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.906\n",
      "FPR: 0.03455194950148892\n",
      "TPR: 0.906\n",
      "F-measure: 0.906319890000543\n",
      "Precision: 0.9106597786107368\n",
      "Recall: 0.906\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName: \"accuracy\"})\n",
    "falsePositiveRate = evaluator.evaluate(prediction, {evaluator.metricName: \"weightedFalsePositiveRate\"})\n",
    "truePositiveRate = evaluator.evaluate(prediction, {evaluator.metricName: \"weightedTruePositiveRate\"})\n",
    "fMeasure = evaluator.evaluate(prediction, {evaluator.metricName: \"weightedFMeasure\"})\n",
    "precision = evaluator.evaluate(prediction, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(prediction, {evaluator.metricName: \"weightedRecall\"})\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617adfc-fd04-4470-892c-6c7248a1f0f5",
   "metadata": {},
   "source": [
    "# Save the model in HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8405368-fe8d-47f5-b6b9-a76f2f8333e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save(\"hdfs://namenode:9000//user/root/model/twitter_lg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
